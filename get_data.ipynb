{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(r\"C:\\dev\\python\\sv-order-2021\\data\\freqs.pickle\", \"rb\") as fhin:\n",
    "\tfreq_d = pickle.load(fhin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL subjects\n",
      "TOKEN, PRE 5,443,243\n",
      "TOKEN, POST 2,875,361\n",
      "LEMMA, PRE 5,443,243\n",
      "LEMMA, POST 2,875,361\n"
     ]
    }
   ],
   "source": [
    "total_subj_token_pre = sum(freq_d[\"subj_token_c\"][\"pre\"].values())\n",
    "total_subj_token_post = sum(freq_d[\"subj_token_c\"][\"post\"].values())\n",
    "total_subj_lemma_pre = sum(freq_d[\"subj_lemma_c\"][\"pre\"].values())\n",
    "total_subj_lemma_post = sum(freq_d[\"subj_lemma_c\"][\"post\"].values())\n",
    "\n",
    "print(\"ALL subjects\")\n",
    "print(\"TOKEN, PRE\", f\"{total_subj_token_pre:,}\")\n",
    "print(\"TOKEN, POST\", f\"{total_subj_token_post:,}\")\n",
    "print(\"LEMMA, PRE\", f\"{total_subj_lemma_pre:,}\")\n",
    "print(\"LEMMA, POST\", f\"{total_subj_lemma_post:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE subjects\n",
      "TOKEN, PRE 305,908\n",
      "TOKEN, POST 172,902\n",
      "LEMMA, PRE 294,209\n",
      "LEMMA, POST 159,786\n"
     ]
    }
   ],
   "source": [
    "uniq_total_subj_token_pre = len(freq_d[\"subj_token_c\"][\"pre\"].keys())\n",
    "uniq_total_subj_token_post = len(freq_d[\"subj_token_c\"][\"post\"].keys())\n",
    "uniq_total_subj_lemma_pre = len(freq_d[\"subj_lemma_c\"][\"pre\"].keys())\n",
    "uniq_total_subj_lemma_post = len(freq_d[\"subj_lemma_c\"][\"post\"].keys())\n",
    "\n",
    "print(\"UNIQUE subjects\")\n",
    "print(\"TOKEN, PRE\", f\"{uniq_total_subj_token_pre:,}\")\n",
    "print(\"TOKEN, POST\", f\"{uniq_total_subj_token_post:,}\")\n",
    "print(\"LEMMA, PRE\", f\"{uniq_total_subj_lemma_pre:,}\")\n",
    "print(\"LEMMA, POST\", f\"{uniq_total_subj_lemma_post:,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL fin verbs\n",
      "TOKEN, PRE 5,443,243\n",
      "TOKEN, POST 2,875,361\n",
      "LEMMA, PRE 5,443,243\n",
      "LEMMA, POST 2,875,361\n"
     ]
    }
   ],
   "source": [
    "total_fin_token_pre = sum(freq_d[\"verb_token_c\"][\"pre\"].values())\n",
    "total_fin_token_post = sum(freq_d[\"verb_token_c\"][\"post\"].values())\n",
    "total_fin_lemma_pre = sum(freq_d[\"verb_lemma_c\"][\"pre\"].values())\n",
    "total_fin_lemma_post = sum(freq_d[\"verb_lemma_c\"][\"post\"].values())\n",
    "\n",
    "print(\"ALL fin verbs\")\n",
    "print(\"TOKEN, PRE\", f\"{total_fin_token_pre:,}\")\n",
    "print(\"TOKEN, POST\", f\"{total_fin_token_post:,}\")\n",
    "print(\"LEMMA, PRE\", f\"{total_fin_lemma_pre:,}\")\n",
    "print(\"LEMMA, POST\", f\"{total_fin_lemma_post:,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE fin verbs\n",
      "TOKEN, PRE 34,993\n",
      "TOKEN, POST 20,543\n",
      "LEMMA, PRE 30,327\n",
      "LEMMA, POST 17,259\n"
     ]
    }
   ],
   "source": [
    "uniq_total_fin_token_pre = len(freq_d[\"verb_token_c\"][\"pre\"].keys())\n",
    "uniq_total_fin_token_post = len(freq_d[\"verb_token_c\"][\"post\"].keys())\n",
    "uniq_total_fin_lemma_pre = len(freq_d[\"verb_lemma_c\"][\"pre\"].keys())\n",
    "uniq_total_fin_lemma_post = len(freq_d[\"verb_lemma_c\"][\"post\"].keys())\n",
    "\n",
    "print(\"UNIQUE fin verbs\")\n",
    "print(\"TOKEN, PRE\", f\"{uniq_total_fin_token_pre:,}\")\n",
    "print(\"TOKEN, POST\", f\"{uniq_total_fin_token_post:,}\")\n",
    "print(\"LEMMA, PRE\", f\"{uniq_total_fin_lemma_pre:,}\")\n",
    "print(\"LEMMA, POST\", f\"{uniq_total_fin_lemma_post:,}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN, MEDIAN SEGS IN WMT TEST 3388.65 1434.5\n"
     ]
    },
    {
     "data": {
      "text/plain": "18286"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lxml\n",
    "from lxml import etree\n",
    "from lxml.etree import ElementTree, Element\n",
    "\n",
    "from pathlib import Path\n",
    "from statistics import mean, median\n",
    "\n",
    "lens = []\n",
    "for pfin in Path(r\"C:\\Users\\bramv\\Downloads\\test-src\").glob(\"*.xml\"):\n",
    "\ttree = etree.parse(str(pfin))\n",
    "\tsegs = tree.findall(\"//seg\")\n",
    "\tlens.append(len(segs))\n",
    "\n",
    "print(\"MEAN, MEDIAN SEGS IN WMT TEST\", mean(lens), median(lens))\n",
    "max(lens)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}